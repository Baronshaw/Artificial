{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络是由一位计算机科学家Yann LeCun所提出的，他在机器学习、计算机视觉和计算神经科学等诸多领域都有贡献。  \n",
    "\n",
    "# 1 卷积神经网络简介  \n",
    "\n",
    "## 1.1 多层感知器与卷积神经网络  \n",
    "\n",
    "如图所示，多层感知器与卷积神网络主要的差异是：卷积神经网络增加了卷积层和池化层的处理来提取特征。  \n",
    "![title](images/8.1.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 卷积神经网络介绍  \n",
    "从上图中可以看到卷积神经网络可以分为两大部分  \n",
    "\n",
    "- 图像的特征提取  \n",
    "通过卷积层1、池化层1、卷积层2、池化层2提取的特征  \n",
    "- 完全连接的神经网络  \n",
    "包含；平坦层、隐藏层、输出层、所组成的类神经网络，如图8-2所示。  \n",
    "<center>![title](images/8.2.png)</center>    \n",
    "从图8-2中，我们可以看到从这些图像中提取了“7”的图像特征，卷积运算的效果类似滤镜效果，即用于提取不同的特征。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 卷积运算  \n",
    "\n",
    "卷积层的的意义是将原本一个图像经过卷积运算产生多个图像，就好像将相片叠加起来。  \n",
    "\n",
    "- 卷积运算的方式  \n",
    "1. 先按照随机的方式产生，filter weight大小是$3\\times 3$。  \n",
    "2. 要转换的图像从左到右、自上而下，按序选取$3\\times 3$的矩阵。  \n",
    "3. 图像选取的矩阵与filter weight乘积，计算第一行，第一列的数字。  \n",
    "![title](images/8.3.png)  \n",
    "再以相同的方式计算第一行、第二列的数字，如下图所示：\n",
    "![title](images/8.4.png)  \n",
    "按照上面的相同方式，按序完成所有运算，就可以完成图像的处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 使用单个filter weight卷积运算产生图像  \n",
    "如图所示：将大小为$28\\times 28$的数字图形3，使用随机产生的$5\\times 5$filter weight滤镜进行卷积运算。  \n",
    "![title](images/8.5.png)  \n",
    "卷积运算并不会改变图形大小，所以处理后的图像大小任然是$28\\times 28$。卷积运算后的效果很类似滤镜效果，这可以帮助我们提取输入的不同特征，例如边缘、线条和角等。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 使用多个filter weight卷积运算产生多个图像  \n",
    "\n",
    "接下来，我们将随机产生16个filter weight，也就是16个滤镜。  \n",
    "卷积运算使用16个滤镜产生16个图像，每个图像提取不同的特征，如图所示。  \n",
    "![title](images/8.6.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Max-Pool运算说明  \n",
    "Max-Pool运算可以对图像缩减采样，如图8-7所示，原本图像是$4\\times 4$的，经过Max-Pooling后，图像大小为$2\\times 2$的。  \n",
    "![title](images/8.7.png)  \n",
    "以上Max-Pooling运算详细说明如下：  \n",
    "\n",
    "- **左上角4个数字：**5、2、4、1最大的是5，所以计算结果是5，如图所示：  \n",
    "![title](images/8.8.png)  \n",
    "\n",
    "- **左上角4个数字：**3、1、1、6最大的是6，所以计算结果是6，如图所示：  \n",
    "![title](images/8.9.png)  \n",
    "\n",
    "- **左上角4个数字：**7、8、1、1最大的是8，所以计算结果是8，如图所示：  \n",
    "![title](images/8.10.png)  \n",
    "\n",
    "- **左上角4个数字：**2、9、1、1最大的是9，所以计算结果是9，如图所示：  \n",
    "![title](images/8.11.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 使用Max-Pooling转换手写数字图像  \n",
    "\n",
    "使用Max-Pooling缩减采样，进行手写数字图像转换，将16个$28\\times 28$的图像缩小为16个$14\\times 14$的图像，但是不会改变图像的数量，如图8-12所示：  \n",
    "![title](images/8.12.png)  \n",
    "缩减采样会缩小图像，有下列好处：  \n",
    "1. **减少需要处理的数据点：**  减少后续运算的时间。  \n",
    "2. **让图像位置差异变小：**例如手写数字7，位置上下左右可能不同，位置的不同可能会影响识别。减小图像大小，让数字的位置差异变小。  \n",
    "3. **参数的数量和计算量下降：**这在一定程度上也控制了过度拟合。  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 建立卷积神经网络识别MNIST数据集  \n",
    "\n",
    "建立卷积神经网络识别MNIST数据集的步骤如图8-13所示。  \n",
    "![title](images/8.13.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 进行数据预处理  \n",
    "\n",
    "卷积神经网络与多层感知器进行数据处理的方式不同，说明见表1。  \n",
    "\n",
    "<center>卷积神经网络与多层感知器进行数据预处理对比</center>  \n",
    "\n",
    "||reshape|说明|  \n",
    "|-----|-----|-----|\n",
    "|多层感知器|image.reshape(60000,784)|多层感知器因为直接送进神经元处理，所以reshpe转换为60000项，每一项有784个数字|\n",
    "|卷积神经网络|image.reshape(60000,28,28,1)|卷积神经网络则要求必须保持图像的维数，所以reshape转换60000项，每一项是$28\\times 28\\times 1$的图像|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入所需模块**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_Train, y_Train), (x_Test, y_Test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Train4D=x_Train.reshape(x_Train.shape[0],28,28,1).astype('float32')\n",
    "x_Test4D=x_Test.reshape(x_Test.shape[0],28,28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Train4D_normalize = x_Train4D / 255\n",
    "x_Test4D_normalize = x_Test4D / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TrainOneHot = np_utils.to_categorical(y_Train)\n",
    "y_TestOneHot = np_utils.to_categorical(y_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**建立模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=16,\n",
    "                 kernel_size=(5,5),\n",
    "                 padding='same',\n",
    "                 input_shape=(28,28,1), \n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 403,242\n",
      "Trainable params: 403,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 0.5272 - acc: 0.8410 - val_loss: 0.1635 - val_acc: 0.9554\n",
      "Epoch 2/20\n",
      " - 20s - loss: 0.2097 - acc: 0.9361 - val_loss: 0.1022 - val_acc: 0.9703\n",
      "Epoch 3/20\n",
      " - 20s - loss: 0.1503 - acc: 0.9549 - val_loss: 0.0805 - val_acc: 0.9773\n",
      "Epoch 4/20\n",
      " - 21s - loss: 0.1249 - acc: 0.9628 - val_loss: 0.0684 - val_acc: 0.9799\n",
      "Epoch 5/20\n",
      " - 21s - loss: 0.1059 - acc: 0.9690 - val_loss: 0.0599 - val_acc: 0.9815\n",
      "Epoch 6/20\n",
      " - 21s - loss: 0.0920 - acc: 0.9723 - val_loss: 0.0568 - val_acc: 0.9833\n",
      "Epoch 7/20\n",
      " - 21s - loss: 0.0838 - acc: 0.9744 - val_loss: 0.0514 - val_acc: 0.9845\n",
      "Epoch 8/20\n",
      " - 21s - loss: 0.0769 - acc: 0.9770 - val_loss: 0.0487 - val_acc: 0.9861\n",
      "Epoch 9/20\n",
      " - 21s - loss: 0.0711 - acc: 0.9776 - val_loss: 0.0458 - val_acc: 0.9861\n",
      "Epoch 10/20\n",
      " - 21s - loss: 0.0656 - acc: 0.9797 - val_loss: 0.0448 - val_acc: 0.9859\n",
      "Epoch 11/20\n",
      " - 21s - loss: 0.0616 - acc: 0.9810 - val_loss: 0.0428 - val_acc: 0.9868\n",
      "Epoch 12/20\n",
      " - 22s - loss: 0.0595 - acc: 0.9814 - val_loss: 0.0424 - val_acc: 0.9878\n",
      "Epoch 13/20\n",
      " - 22s - loss: 0.0536 - acc: 0.9836 - val_loss: 0.0411 - val_acc: 0.9877\n",
      "Epoch 14/20\n",
      " - 22s - loss: 0.0485 - acc: 0.9846 - val_loss: 0.0400 - val_acc: 0.9883\n",
      "Epoch 15/20\n",
      " - 22s - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0397 - val_acc: 0.9887\n",
      "Epoch 16/20\n",
      " - 21s - loss: 0.0452 - acc: 0.9857 - val_loss: 0.0375 - val_acc: 0.9894\n",
      "Epoch 17/20\n",
      " - 21s - loss: 0.0423 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9894\n",
      "Epoch 18/20\n",
      " - 21s - loss: 0.0430 - acc: 0.9858 - val_loss: 0.0393 - val_acc: 0.9896\n",
      "Epoch 19/20\n",
      " - 21s - loss: 0.0407 - acc: 0.9862 - val_loss: 0.0369 - val_acc: 0.9899\n",
      "Epoch 20/20\n"
     ]
    }
   ],
   "source": [
    "train_history=model.fit(x=x_Train4D_normalize, \n",
    "                        y=y_TrainOneHot,validation_split=0.2, \n",
    "                        epochs=20, batch_size=300,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_acc,test_acc):\n",
    "    plt.plot(train_history.history[train_acc])\n",
    "    plt.plot(train_history.history[test_acc])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history('acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_Test4D_normalize , y_TestOne Hot)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict_classes(x_Test4D_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看预测结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images_labels_prediction(images,labels,prediction,idx,num=10):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12, 14)\n",
    "    if num>25: num=25 \n",
    "    for i in range(0, num):\n",
    "        ax=plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[idx], cmap='binary')\n",
    "\n",
    "        ax.set_title(\"label=\" +str(labels[idx])+\n",
    "                     \",predict=\"+str(prediction[idx])\n",
    "                     ,fontsize=10) \n",
    "        \n",
    "        ax.set_xticks([]);ax.set_yticks([])        \n",
    "        idx+=1 \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_labels_prediction(x_Test,y_Test,prediction,idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**混淆矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.crosstab(y_Test,prediction,\n",
    "            rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label':y_Test, 'predict':prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.label==5)&(df.predict==3)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
